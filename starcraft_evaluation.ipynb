{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "When predicting player rank from the starcraft player data, at first glance it seems as though the accuracy from the test data is not accurate. The best performing model, the **Random Forest with LogLog Transformation**, only predicted the correct rank around 41.6% of the time. In terms of results that may seem bad, but looking at the **mean absolute error**, meaning on average how far away the model was predicting from the accurate rank, it was only 0.72, less than a complete rank. This means that if the player was a GrandMaster, 40 percent of the time the model would be able to predict it correctly. **However, if it was not predicted correctly, more often than not the model would predict the player to be one rank above or one rank below**. Thus, I believe this classification project to be greatly successful, as the model is not too far off from the real rank. If someone was LeagueIndex 6, usually the model will predict somewhere in the range of 5-7, which is still similar in skill level. Upon further analysis, the model performing pretty average across all ranks, being the best at predicting 8 while being the worst at predicting 7. This can be attributed to a number of reasons. As mentioned before, the KNN Imputer put extreme values for TotalHours when LeagueIndex = 8. This means that any modeling method will have an easier time predicting 8 due to that fact. Additionally, I believe the low amount of player data on LeagueIndex = 7 makes it difficult to predict accurately. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "In terms of improvements to this project, I think there are a few that could be addressed. Primarily, the lack of player data in all of the Professional players means that there is a lot of innacuracies when it comes to estimating data. If we had some Professional players with TotalHours or HoursPerWeek, then the estimations would be more accurate. Additionally, there are various other classification methods that could be effective in predicting player rank. For example, SVMs, Gradient Boosting, Lasso, or other various methods could produce different results, but I don't think they would produce a result that is significantly better than the ones tested above. I believe multiple fold validation alongside mixing models could maximize prediction accuracy.\n",
    "\n",
    "When addresssing the hypothetical task of collecting more data, there are several things I could think of that can improve the model. As mentioned before, a larger amount of data, specifically for GrandMaster and Professional players, would improve classification greatly. However, I must concede that it may be proven difficult, due to the fact that most game rank distributions follow a normally distributed curve. Thus, my only concession would be to have the missing values filled, especially for the professional players. Addtionally, I would also suggest to provide more information regarding the games itself. For example, there are multiple races present in Starcraft from my brief analysis of the game. What character were they playing? Certain players might be better at playing a certain character, and also the character that the enemy is playing could be an important factor as well. Improving data collection would absolutely increase better modeling. One thing to consider is that Starcraft is playable from multiple different regions such as the US, Europe, and Korea. Thus, labeling region or being able to collect data from the different regions would also be an interesting piece of data to have. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
